{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 분류 모델\n",
    "\n",
    "![Screenshot 2024-01-25 at 3.08.44 PM.png](https://kr.object.ncloudstorage.com/docent/Screenshot%202024-01-25%20at%203.08.44%20PM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다음과 같은 순서로 진행합니다.\n",
    "\n",
    "1. 데이터셋 라벨링\n",
    "2. 데이터셋 로드\n",
    "3. 모델링\n",
    "4. 모델 훈련\n",
    "5. 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 라벨링\n",
    "\n",
    "- 서비스에서 gpt-4-turbo모델로 분류한 데이터셋을 불러옵니다.\n",
    "- 약 2600개의 데이터를 직접 검수하여 라벨링합니다.\n",
    "\n",
    "![Screenshot 2024-01-24 at 4.51.36 PM.png](https://kr.object.ncloudstorage.com/docent/Screenshot%202024-01-24%20at%204.51.36%20PM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install datasets\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 25 17:17:16 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:01:00.0 Off |                  Off |\n",
      "|  0%   38C    P8              33W / 450W |   5476MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1524      G   /usr/lib/xorg/Xorg                           72MiB |\n",
      "|    0   N/A  N/A      1838      G   /usr/bin/gnome-shell                         61MiB |\n",
      "|    0   N/A  N/A    341524      C   /usr/bin/python                            5322MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 로드\n",
    "\n",
    "- 라벨링한 데이터셋을 불러옵니다.\n",
    "- gpt-4-turbo모델로 분류한 데이터셋의 f1-score를 확인합니다. (macro avg)\n",
    "- 데이터셋을 train, test로 분리합니다.\n",
    "- train셋을 stratified k-fold로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에 gpt-4-turbo 모델로 사용자의 텍스트를 분류하는 prompt\n",
    "\n",
    "prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"사용자의 텍스트가 꿈, 일기, 메모, 일정 중 어떤 카테고리인지 분류해서 숫자만 반환해줘. 꿈 = 1, 일기 = 2, 메모 = 3, 일정 = 4\"},\n",
    "    {\"role\": \"system\", \"content\": \"내용이 짧으면 메모 또는 일정일 확률이 높고, 꿈이라는 단어가 포함되면 꿈, 오늘 내가 한 일들과 생각들이 포함되면 일기일 확률이 높다.\"},\n",
    "    {\"role\": \"system\", \"content\": \"날짜와 관련된 단어가 포함되면 일정일 확률이 높다.\"},\n",
    "    {\"role\": \"system\", \"content\": \"나머지는 메모로 분류해줘. return 1, 2, 3, 4\"},\n",
    "    {\"role\": \"user\", \"content\": \"엄청나게 맑고 깨끗한 낚시터에서 낚시했는데 어찌나 투명한지 물고기가 다 보이는 꿈\"},\n",
    "    {\"role\": \"system\", \"content\": \"1\"},\n",
    "    {\"role\": \"user\", \"content\": \"오늘은 하루종일 코딩을 했다. 내가 만든 코드는 잘 돌아가지 않고, 너무 고통받았다. 내일은 개발을 마무리해서 얼른 서비스를 출시하고 싶다\"},\n",
    "    {\"role\": \"system\", \"content\": \"2\"},\n",
    "    {\"role\": \"user\", \"content\": \"엘리스 세습 책 읽기, 56쪽\"},\n",
    "    {\"role\": \"system\", \"content\": \"3\"},\n",
    "    {\"role\": \"user\", \"content\": \"8월25일 저녁6시 강남 약속\"},\n",
    "    {\"role\": \"system\", \"content\": \"4\"},\n",
    "    {\"role\": \"user\", \"content\": \"오늘은 크리스마스다. 여자친구와 현대백화점에 가서 아웃백을 먹고 영화를 봤다. 오펜하이머를 봤는데 나는 사실 물리학과를 갔어야 될 것 같다. 너무 재미있었다.\"},\n",
    "    {\"role\": \"system\", \"content\": \"2\"},\n",
    "    {\"role\": \"user\", \"content\": \"다음주 금요일 6시에 중앙도서관 앞에서 자동차 동아리 모임이 있어\"},\n",
    "    {\"role\": \"system\", \"content\": \"4\"},\n",
    "    {\"role\": \"user\", \"content\": \"스키장에서 스키를 타고 있는데 뒤에서 곰이 갑자기 튀어나와서 도망가다가 넘어지고, 꿈에서 깼어\"},\n",
    "    {\"role\": \"system\", \"content\": \"1\"},\n",
    "    {\"role\": \"user\", \"content\": \"꿈에서 어떤 길에서 있었는데 하을을 올려보니 보름달이 구름에 가려져 빛나고 있었다. 구름에 가려졌지만 밝게 빛나고 있어서 보름달이 잘 보였다. 보름달은 이내 구름 위로 솟아 올라 밝게 빛났다.\"},\n",
    "    {\"role\": \"system\", \"content\": \"1\"},\n",
    "    {\"role\": \"user\", \"content\": \"학교에서 계속 공부를했다. 너무 힘든 하루였지만 마무리가 깔끔해서 기분좋게 잠에 잘 수 있을 것 같다. 내일은 더 열심히 해야겠다.\"},\n",
    "    {\"role\": \"system\", \"content\": \"2\"},\n",
    "    {\"role\": \"user\", \"content\": \"11월 20일부터 28일은 부산으로 여행갈거야\"},\n",
    "    {\"role\": \"system\", \"content\": \"4\"},\n",
    "    {\"role\": \"user\", \"content\": \"오늘 내역서 작업하느라 매우 바빴는데 저녁에 회를 먹어서 호다닥 달려옴\"},\n",
    "    {\"role\": \"system\", \"content\": \"2\"},\n",
    "    {\"role\": \"user\", \"content\": \"아침마다 파업 그만했으면 좋겠다 한놈만 걸려라 다 패버린다\"},\n",
    "    {\"role\": \"system\", \"content\": \"2\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labeled_output</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>오늘은 소망 누나랑 자전거를 탔다. 날씨가 참 좋았다</td>\n",
       "      <td>일기</td>\n",
       "      <td>일기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>소망누나랑 자전거를 타는 꿈을 꿨어</td>\n",
       "      <td>꿈</td>\n",
       "      <td>꿈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>소망누나랑 자전거를 타는 꿈을 꿨어</td>\n",
       "      <td>꿈</td>\n",
       "      <td>꿈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>오늘은 팀원들이랑 열심히 회의했고, 만족스러운 하루였다.</td>\n",
       "      <td>일기</td>\n",
       "      <td>일기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>산에서 곰이 내려와서 우리집 문을 부시고 가는 꿈을 꿨어</td>\n",
       "      <td>꿈</td>\n",
       "      <td>꿈</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text labeled_output output\n",
       "0    오늘은 소망 누나랑 자전거를 탔다. 날씨가 참 좋았다             일기     일기\n",
       "1              소망누나랑 자전거를 타는 꿈을 꿨어              꿈      꿈\n",
       "2              소망누나랑 자전거를 타는 꿈을 꿨어              꿈      꿈\n",
       "3  오늘은 팀원들이랑 열심히 회의했고, 만족스러운 하루였다.             일기     일기\n",
       "4  산에서 곰이 내려와서 우리집 문을 부시고 가는 꿈을 꿨어              꿈      꿈"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/media/mydrive/datasets/text_classification.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 2678\n",
      "Number of differences: 462\n",
      "Correct ratio of GPT: 82.74831964152352%\n"
     ]
    }
   ],
   "source": [
    "total_count = df.shape[0]\n",
    "difference_count = (df['labeled_output'] != df['output']).sum()\n",
    "\n",
    "print(f\"Total number of rows: {total_count}\")\n",
    "print(f\"Number of differences: {difference_count}\")\n",
    "print(f\"Correct ratio of GPT: {100 - (difference_count / total_count * 100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6730143123728515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 레이블과 예측 결과를 리스트 형태로 변환\n",
    "labels = df['labeled_output'].tolist()\n",
    "predictions = df['output'].tolist()\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1 = f1_score(labels, predictions, average='macro')  # 'macro'는 클래스 불균형을 고려하지 않음\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT output distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "output\n",
       "꿈     704\n",
       "일정    698\n",
       "일기    674\n",
       "메모    602\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"GPT output distribution:\")\n",
    "df['output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled output distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "labeled_output\n",
       "일기    729\n",
       "일정    729\n",
       "꿈     655\n",
       "메모    377\n",
       "오류    188\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Labeled output distribution:\")\n",
    "\n",
    "df['labeled_output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold 1 저장 완료: /media/mydrive/datasets/text_classification_train_fold_1.jsonl\n",
      "Train Fold 2 저장 완료: /media/mydrive/datasets/text_classification_train_fold_2.jsonl\n",
      "Train Fold 3 저장 완료: /media/mydrive/datasets/text_classification_train_fold_3.jsonl\n",
      "Train Fold 4 저장 완료: /media/mydrive/datasets/text_classification_train_fold_4.jsonl\n",
      "Train Fold 5 저장 완료: /media/mydrive/datasets/text_classification_train_fold_5.jsonl\n",
      "Test 데이터셋 저장 완료: /media/mydrive/datasets/text_classification_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import json\n",
    "\n",
    "# 전체 데이터셋을 훈련 세트와 테스트 세트로 분리\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 훈련 세트를 섞음\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# StratifiedKFold 인스턴스 생성\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 훈련 세트의 Fold 별로 데이터를 나누고 jsonl 파일로 저장\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(train_df, train_df['labeled_output']), 1):\n",
    "    fold_data = train_df.iloc[test_index]\n",
    "\n",
    "    file_name = f'/media/mydrive/datasets/text_classification_train_fold_{fold}.jsonl'\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        for i, (_, row) in enumerate(fold_data.iterrows()):\n",
    "            if type(row[\"text\"]) != str:\n",
    "                continue \n",
    "            data = {\"id\": i, \"input\": row['text'], \"output\": row['labeled_output']}\n",
    "            json.dump(data, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "    print(f'Train Fold {fold} 저장 완료: {file_name}')\n",
    "\n",
    "# 테스트 세트를 jsonl 파일로 저장\n",
    "test_file_name = '/media/mydrive/datasets/text_classification_test.jsonl'\n",
    "with open(test_file_name, 'w', encoding='utf-8') as f:\n",
    "    for i, (_, row) in enumerate(test_df.iterrows()):\n",
    "        if type(row[\"text\"]) != str:\n",
    "            continue \n",
    "        data = {\"id\": i, \"input\": row['text'], \"output\": row['labeled_output']}\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(f'Test 데이터셋 저장 완료: {test_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기: 2142\n",
      "테스트 데이터의 크기: 536\n",
      "{\"id\": 0, \"input\": \"11월 22일에서 23일 오후 1시부터 오전 12시까지 강릉 여행\", \"output\": \"일정\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"훈련 데이터의 크기: {train_df.shape[0]}\")\n",
    "print(f\"테스트 데이터의 크기: {test_df.shape[0]}\")\n",
    "\n",
    "# 데이터 하나 확인\n",
    "with open('/media/mydrive/datasets/text_classification_fold_1.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링 및 모델 훈련\n",
    "- huggingface에서 모델을 불러옵니다.\n",
    "- 데이터셋을 토크나이징합니다.\n",
    "- Stratified k-fold cross validation 방식으로 모델을 훈련합니다.\n",
    "- early stopping을 적용합니다.\n",
    "- f1-score를 확인합니다.(macro avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification, ElectraConfig, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 매핑\n",
    "label_map = {'꿈': 0, '일기': 1, '일정': 2, '메모': 3, '오류': 4}\n",
    "\n",
    "#epoch 설정\n",
    "epochs = 9999\n",
    "\n",
    "# 학습률\n",
    "lr = 1e-5\n",
    "\n",
    "# early stopping 횟수\n",
    "early_stop_patient = 5\n",
    "\n",
    "# wandb 설정\n",
    "weight_decay = 0.01\n",
    "\n",
    "# k-fold 설정\n",
    "k = 5\n",
    "\n",
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 모델 이름\n",
    "model_name = \"beomi/KcELECTRA-base-v2022\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:roszxs4n) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>1fold_eval_f1</td><td>▁▂▄▅▅▆▇▇███▇█</td></tr><tr><td>1fold_train_loss</td><td>█▆▄▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>2fold_eval_f1</td><td>▁▂▄▅▅▆▆████████▇████▇</td></tr><tr><td>2fold_train_loss</td><td>█▆▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>3fold_eval_f1</td><td>▁▃▅▅▆▇▇████████</td></tr><tr><td>3fold_train_loss</td><td>█▆▄▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>4fold_eval_f1</td><td>▁▂▄▅▅▅▇▇▇▇▇▇█▇▇██▇█████████████</td></tr><tr><td>4fold_train_loss</td><td>█▆▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>5fold_eval_f1</td><td>▁▂▅▅▅▇▇▇▇▇▇█▇██████</td></tr><tr><td>5fold_train_loss</td><td>█▆▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>1fold_eval_f1</td><td>0.87338</td></tr><tr><td>1fold_train_loss</td><td>0.13981</td></tr><tr><td>2fold_eval_f1</td><td>0.86043</td></tr><tr><td>2fold_train_loss</td><td>0.0716</td></tr><tr><td>3fold_eval_f1</td><td>0.86108</td></tr><tr><td>3fold_train_loss</td><td>0.08822</td></tr><tr><td>4fold_eval_f1</td><td>0.87441</td></tr><tr><td>4fold_train_loss</td><td>0.04335</td></tr><tr><td>5fold_eval_f1</td><td>0.86816</td></tr><tr><td>5fold_train_loss</td><td>0.06736</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">5_1e-05_32_text_classification</strong>: <a href=\"https://wandb.ai/taewan2002/text_classification/runs/roszxs4n\" target=\"_blank\">https://wandb.ai/taewan2002/text_classification/runs/roszxs4n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240125_155923-roszxs4n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:roszxs4n). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dmz/wandb/run-20240125_171717-d9jt58q2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/taewan2002/text_classification/runs/d9jt58q2\" target=\"_blank\">5_1e-05_32_text_classification</a></strong> to <a href=\"https://wandb.ai/taewan2002/text_classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'ElectraTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 2142\n",
      "Dev dataset: 536\n",
      "Train dataset label distribution: (tensor([0, 1, 2, 3, 4]), tensor([506, 594, 584, 305, 153]))\n",
      "Dev dataset label distribution: (tensor([0, 1, 2, 3, 4]), tensor([153, 132, 139,  79,  33]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/dmz/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.4300595468549586\n",
      "Epoch 1 | Eval F1 score: 0.396040387000555\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.0274460111091386\n",
      "Epoch 2 | Eval F1 score: 0.6036610589570506\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.6572975814342499\n",
      "Epoch 3 | Eval F1 score: 0.6922764745893836\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.4955193645028926\n",
      "Epoch 4 | Eval F1 score: 0.6924595368334027\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.41231889733627664\n",
      "Epoch 5 | Eval F1 score: 0.7086604751201935\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.3452457380828573\n",
      "Epoch 6 | Eval F1 score: 0.8081077531975703\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|█████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.30068254281780615\n",
      "Epoch 7 | Eval F1 score: 0.8496667583368984\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.2613324094841729\n",
      "Epoch 8 | Eval F1 score: 0.8700425332986612\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.2254193667600404\n",
      "Epoch 9 | Eval F1 score: 0.8941347158601328\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.19716528502862846\n",
      "Epoch 10 | Eval F1 score: 0.8851690946167425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.1644984815658918\n",
      "Epoch 11 | Eval F1 score: 0.8840610583814368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.1388342136433765\n",
      "Epoch 12 | Eval F1 score: 0.8867597758904205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.12582100202232155\n",
      "Epoch 13 | Eval F1 score: 0.9000600415514451\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.1063625453623818\n",
      "Epoch 14 | Eval F1 score: 0.8865891008104331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.10818149724891826\n",
      "Epoch 15 | Eval F1 score: 0.9012792957474403\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.09017098820142781\n",
      "Epoch 16 | Eval F1 score: 0.8969758884442568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.07513802943389807\n",
      "Epoch 17 | Eval F1 score: 0.8919388539965233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.07867169327366708\n",
      "Epoch 18 | Eval F1 score: 0.9064552266639282\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.06918833721707117\n",
      "Epoch 19 | Eval F1 score: 0.9026620444295459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.06884228218513638\n",
      "Epoch 20 | Eval F1 score: 0.8922521796534875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.05809593666344881\n",
      "Epoch 21 | Eval F1 score: 0.9008715355602182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.0662637949684885\n",
      "Epoch 22 | Eval F1 score: 0.9033185697525908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.05577284568892931\n",
      "Epoch 23 | Eval F1 score: 0.9169208510040969\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.051551763670268785\n",
      "Epoch 24 | Eval F1 score: 0.9034741692620443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.04966961594520888\n",
      "Epoch 25 | Eval F1 score: 0.9058639266912504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.04562511422268268\n",
      "Epoch 26 | Eval F1 score: 0.8919082430482336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.03852165333315063\n",
      "Epoch 27 | Eval F1 score: 0.9054671655794401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|████████████████████████████████████████████████████████| 67/67 [00:18<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.03506103652154109\n",
      "Epoch 28 | Eval F1 score: 0.9065702997552773\n",
      "Best F1 for 1: 0.9169208510040969\n",
      "Training for fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'ElectraTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 2142\n",
      "Dev dataset: 536\n",
      "Train dataset label distribution: (tensor([0, 1, 2, 3, 4]), tensor([526, 577, 580, 309, 150]))\n",
      "Dev dataset label distribution: (tensor([0, 1, 2, 3, 4]), tensor([133, 149, 143,  75,  36]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/dmz/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.4457813786036933\n",
      "Epoch 1 | Eval F1 score: 0.4612619701491507\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.0456388708370834\n",
      "Epoch 2 | Eval F1 score: 0.5729932882925121\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.6878025456150966\n",
      "Epoch 3 | Eval F1 score: 0.6679836611691192\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.5188663535153688\n",
      "Epoch 4 | Eval F1 score: 0.682454878266656\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.42715377216018846\n",
      "Epoch 5 | Eval F1 score: 0.6965551047712192\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.35533641056338355\n",
      "Epoch 6 | Eval F1 score: 0.7821093805926109\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.30432561195608393\n",
      "Epoch 7 | Eval F1 score: 0.8532612131882189\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.2669095577143911\n",
      "Epoch 8 | Eval F1 score: 0.8595412455437508\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.22544886483185328\n",
      "Epoch 9 | Eval F1 score: 0.85735008921712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.21195334985629835\n",
      "Epoch 10 | Eval F1 score: 0.8669816157621035\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.17433833531034526\n",
      "Epoch 11 | Eval F1 score: 0.8698305068074234\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.1398544164179866\n",
      "Epoch 12 | Eval F1 score: 0.8946604326794839\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.13315766688380667\n",
      "Epoch 13 | Eval F1 score: 0.8733675789698918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.12555593305003288\n",
      "Epoch 14 | Eval F1 score: 0.895748732078826\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.10603469977183129\n",
      "Epoch 15 | Eval F1 score: 0.8831619874594032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.10332256719581227\n",
      "Epoch 16 | Eval F1 score: 0.8667656618173988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.08878971689116599\n",
      "Epoch 17 | Eval F1 score: 0.8756896157965569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.07828994167607221\n",
      "Epoch 18 | Eval F1 score: 0.8841595094181655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.07111683258536591\n",
      "Epoch 19 | Eval F1 score: 0.8708510975625284\n",
      "Best F1 for 2: 0.895748732078826\n",
      "Training for fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'ElectraTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 2142\n",
      "Dev dataset: 536\n",
      "Train dataset label distribution: (tensor([0, 1, 2, 3, 4]), tensor([536, 584, 570, 304, 148]))\n",
      "Dev dataset label distribution: (tensor([0, 1, 2, 3, 4]), tensor([123, 142, 153,  80,  38]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/dmz/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.4243300672787338\n",
      "Epoch 1 | Eval F1 score: 0.4701410060104669\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.002781851967769\n",
      "Epoch 2 | Eval F1 score: 0.5401350413065569\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.6646170171339121\n",
      "Epoch 3 | Eval F1 score: 0.6516182969734968\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.4940706467005744\n",
      "Epoch 4 | Eval F1 score: 0.6695878737138625\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.40182562261375027\n",
      "Epoch 5 | Eval F1 score: 0.6797118202292005\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.34057467886761056\n",
      "Epoch 6 | Eval F1 score: 0.6915602562181975\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.2971866139725073\n",
      "Epoch 7 | Eval F1 score: 0.8003943188893989\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.25034547597169876\n",
      "Epoch 8 | Eval F1 score: 0.8604936463948555\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.2182753031600767\n",
      "Epoch 9 | Eval F1 score: 0.868188039689166\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.17384230512291637\n",
      "Epoch 10 | Eval F1 score: 0.8580207643942657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.1452107097008335\n",
      "Epoch 11 | Eval F1 score: 0.8528253197747546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.13531624347861135\n",
      "Epoch 12 | Eval F1 score: 0.8550472142608369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.1144383713158209\n",
      "Epoch 13 | Eval F1 score: 0.8572836904870528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.09356158001542982\n",
      "Epoch 14 | Eval F1 score: 0.8535095497332179\n",
      "Best F1 for 3: 0.868188039689166\n",
      "Training for fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'ElectraTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 2143\n",
      "Dev dataset: 535\n",
      "Train dataset label distribution: (tensor([0, 1, 2, 3, 4]), tensor([538, 569, 591, 300, 145]))\n",
      "Dev dataset label distribution: (tensor([0, 1, 2, 3, 4]), tensor([121, 157, 132,  84,  41]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/dmz/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.4294964537691714\n",
      "Epoch 1 | Eval F1 score: 0.4721246226809258\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.0091402521773951\n",
      "Epoch 2 | Eval F1 score: 0.6358479017104762\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.6297051030308453\n",
      "Epoch 3 | Eval F1 score: 0.6734722179744658\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.4562963222834601\n",
      "Epoch 4 | Eval F1 score: 0.686513364443923\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.38299222357237517\n",
      "Epoch 5 | Eval F1 score: 0.7469842138527392\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.32227309492986594\n",
      "Epoch 6 | Eval F1 score: 0.7717451131605231\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.2698312667545988\n",
      "Epoch 7 | Eval F1 score: 0.8416707502631373\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.23801635717278097\n",
      "Epoch 8 | Eval F1 score: 0.8445929055561665\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.20102601943176185\n",
      "Epoch 9 | Eval F1 score: 0.8457652986009533\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.17810483065558902\n",
      "Epoch 10 | Eval F1 score: 0.8642166744408971\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.15317311899653122\n",
      "Epoch 11 | Eval F1 score: 0.8522203790845246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.1400506557590926\n",
      "Epoch 12 | Eval F1 score: 0.8449494135553766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.14173381925741238\n",
      "Epoch 13 | Eval F1 score: 0.8567678739051929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.11027836296429384\n",
      "Epoch 14 | Eval F1 score: 0.8474323861440913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.11766847167442095\n",
      "Epoch 15 | Eval F1 score: 0.8615122286008361\n",
      "Best F1 for 4: 0.8642166744408971\n",
      "Training for fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'ElectraTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 2143\n",
      "Dev dataset: 535\n",
      "Train dataset label distribution: (tensor([0, 1, 2, 3, 4]), tensor([530, 580, 567, 318, 148]))\n",
      "Dev dataset label distribution: (tensor([0, 1, 2, 3, 4]), tensor([129, 146, 156,  66,  38]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/dmz/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.4423635219460103\n",
      "Epoch 1 | Eval F1 score: 0.47974818946885983\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.0226660237383487\n",
      "Epoch 2 | Eval F1 score: 0.6524699853656909\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.650356050747544\n",
      "Epoch 3 | Eval F1 score: 0.6780881907526871\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.4786161827062493\n",
      "Epoch 4 | Eval F1 score: 0.6876684562372517\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.38860821946343377\n",
      "Epoch 5 | Eval F1 score: 0.6963035563692241\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.3549628640288737\n",
      "Epoch 6 | Eval F1 score: 0.7290496511605365\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.31368513483164917\n",
      "Epoch 7 | Eval F1 score: 0.7617118494099195\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.26709181459537196\n",
      "Epoch 8 | Eval F1 score: 0.8122007331385822\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.2217501156143288\n",
      "Epoch 9 | Eval F1 score: 0.8341676353167955\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.18744594186766825\n",
      "Epoch 10 | Eval F1 score: 0.8534266411866314\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.1751218487633698\n",
      "Epoch 11 | Eval F1 score: 0.8603109724705348\n",
      "Best epoch ! saved the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.1515118876166308\n",
      "Epoch 12 | Eval F1 score: 0.8441669900348389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.13854256722686895\n",
      "Epoch 13 | Eval F1 score: 0.8597420787925252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.1110306842002406\n",
      "Epoch 14 | Eval F1 score: 0.8493648740223521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.11862828090453326\n",
      "Epoch 15 | Eval F1 score: 0.846367583366258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|████████████████████████████████████████████████████████| 67/67 [00:19<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.11359084995268885\n",
      "Epoch 16 | Eval F1 score: 0.8448030115262567\n",
      "Best F1 for 5: 0.8603109724705348\n"
     ]
    }
   ],
   "source": [
    "# wandb 설정\n",
    "config = {\n",
    "    \"model_name\": \"beomi/KcELECTRA-base-v2022\",\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"wandb\": True,\n",
    "    \"early_stop_patient\" : early_stop_patient,\n",
    "    \"K-Fold\" : '5'\n",
    "}\n",
    "wandb_name = f'{k}_{lr}_{batch_size}_text_classification'\n",
    "wandb.init(project=\"text_classification\", entity=\"taewan2002\", name=wandb_name)\n",
    "\n",
    "def load_and_process_data(file_path, label_map):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    texts = [item['input'] for item in data]\n",
    "    label_list = [label_map[item['output']] for item in data]\n",
    "    return texts, label_list\n",
    "\n",
    "\n",
    "for kfold in range(1, k + 1):\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Training for fold {kfold}\")\n",
    "\n",
    "    # 토크나이저 로드\n",
    "    tokenizer = ElectraTokenizer.from_pretrained(model_name, cache_dir=\"/media/mydrive/base_models\")\n",
    "\n",
    "    # 데이터 토크나이징\n",
    "    def tokenize_data(texts):\n",
    "        # padding과 truncation을 True로 설정하면 배치 내 최대 길이로 패딩\n",
    "        # return_tensors=\"pt\"를 통해 PyTorch의 Tensor로 변환\n",
    "        return tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    def create_dataset(tokenized_data, labels):\n",
    "        # input_ids, attention_mask를 텐서로 변환\n",
    "        input_ids = tokenized_data['input_ids']\n",
    "        attention_mask = tokenized_data['attention_mask']\n",
    "        return TensorDataset(input_ids, attention_mask, torch.tensor(labels))\n",
    "    \n",
    "    dev_file = f\"/media/mydrive/datasets/text_classification_fold_{kfold}.jsonl\"\n",
    "    train_files = [f\"/media/mydrive/datasets/text_classification_fold_{i}.jsonl\" for i in range(1, 6) if i != kfold]\n",
    "    \n",
    "    train_texts, train_labels = [], []\n",
    "    for train_file in train_files:\n",
    "        texts, labels = load_and_process_data(train_file, label_map)\n",
    "        train_texts.extend(texts)\n",
    "        train_labels.extend(labels)\n",
    "\n",
    "    tokenized_train = tokenize_data(train_texts)\n",
    "    train_dataset = create_dataset(tokenized_train, train_labels)\n",
    "\n",
    "    dev_texts, dev_labels = load_and_process_data(dev_file, label_map)\n",
    "    tokenized_dev = tokenize_data(dev_texts)\n",
    "    dev_dataset = create_dataset(tokenized_dev, dev_labels)\n",
    "\n",
    "    print(f\"Train dataset: {len(train_dataset)}\")\n",
    "    print(f\"Dev dataset: {len(dev_dataset)}\")\n",
    "    print(f\"Train dataset label distribution: {torch.unique(train_dataset.tensors[2], return_counts=True)}\")\n",
    "    print(f\"Dev dataset label distribution: {torch.unique(dev_dataset.tensors[2], return_counts=True)}\")\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dev_dataloader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # cuda 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 모델 로드\n",
    "    config = ElectraConfig.from_pretrained(model_name, cache_dir=\"/media/mydrive/base_models\")\n",
    "    config.hidden_dropout_prob = 0.2 # dropout 설정\n",
    "    config.num_labels=len(label_map) # 라벨 개수 설정\n",
    "    model = ElectraForSequenceClassification.from_pretrained(model_name, cache_dir=\"/media/mydrive/base_models\", config=config, ).to(device)\n",
    "\n",
    "    # optimizer 설정\n",
    "    FULL_FINETUNING = True\n",
    "    if FULL_FINETUNING:\n",
    "        entity_property_param_optimizer = list(model.named_parameters()) # 모델의 파라미터를 불러옴\n",
    "        no_decay = ['bias', 'LayerNorm.weight'] # 파라미터 중에서 weight decay를 적용하지 않을 파라미터를 설정\n",
    "        entity_property_optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in entity_property_param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay_rate': weight_decay},\n",
    "            {'params': [p for n, p in entity_property_param_optimizer if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay_rate': 0.0}\n",
    "        ] # weight decay를 적용할 파라미터와 적용하지 않을 파라미터를 그룹화\n",
    "    optimizer = AdamW(entity_property_optimizer_grouped_parameters, lr=lr) # AdamW optimizer를 설정\n",
    "\n",
    "    early_stop_counter = 0\n",
    "    best_f1 = 0\n",
    "\n",
    "    for epoch in range(epochs): # epoch만큼 반복, eraly stopping을 적용\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
    "            batch_input_ids, batch_attention_mask, batch_labels = [b.to(device) for b in batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask, labels=batch_labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} | Train Loss: {total_loss / len(train_dataloader)}\")\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_true = []\n",
    "\n",
    "        with torch.no_grad(): # 평가할 때는 그래디언트 계산을 수행하지 않음\n",
    "            for batch in dev_dataloader:\n",
    "                batch_input_ids, batch_attention_mask, batch_labels = [b.to(device) for b in batch]\n",
    "                \n",
    "                outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
    "                preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()  # GPU에서 CPU로 옮기고 NumPy 배열로 변환\n",
    "\n",
    "                all_preds.extend(preds)\n",
    "                all_true.extend(batch_labels.cpu().numpy())  # GPU에서 CPU로 옮기고 NumPy 배열로 변환\n",
    "\n",
    "                \n",
    "        f1 = f1_score(all_true, all_preds, average = \"macro\") # F1 score 계산\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1} | Eval F1 score: {f1}\")\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            print(\"Best epoch ! saved the model\")\n",
    "            best_f1 = f1\n",
    "            early_stop_counter = 0\n",
    "            model.save_pretrained(f\"/media/mydrive/models/text_classification/model_{kfold}\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter >= early_stop_patient:\n",
    "            break\n",
    "            \n",
    "        wandb.log({f\"{kfold}fold_train_loss\": total_loss / len(train_dataloader), f\"{kfold}fold_eval_f1\": f1})\n",
    "        \n",
    "    del model # 모델 삭제\n",
    "    torch.cuda.empty_cache() # GPU 캐시 삭제\n",
    "    print(f\"Best F1 for {kfold}: {best_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치사이즈 32로 했을 때, 17gb정도 메모리를 사용하였습니다.\n",
    "\n",
    "![Screenshot 2024-01-25 at 3.18.14 PM.png](https://kr.object.ncloudstorage.com/docent/Screenshot%202024-01-25%20at%203.18.14%20PM.png)\n",
    "\n",
    "wandb로 학습을 모니터링하였습니다.\n",
    "\n",
    "![Screenshot 2024-01-25 at 4.39.32 PM.png](https://kr.object.ncloudstorage.com/docent/Screenshot%202024-01-25%20at%204.39.32%20PM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가\n",
    "\n",
    "- test셋을 이용하여 모델을 평가합니다.\n",
    "- k개의 모델으로 평가한 결과를 평균내어 최종 f1-score를 확인합니다. (macro avg)\n",
    "- gpt-4-turbo모델과 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: 536\n",
      "F1 Score for fold 1: 0.9579168072253672\n",
      "F1 Score for fold 2: 0.9614135559040007\n",
      "F1 Score for fold 3: 0.9506633558716269\n",
      "F1 Score for fold 4: 0.94866333629038\n",
      "F1 Score for fold 5: 0.9420034775694255\n",
      "Average F1 Score: 0.9521321065721601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import json\n",
    "\n",
    "# 테스트 데이터 로드 및 처리\n",
    "test_file_name = '/media/mydrive/datasets/text_classification_test.jsonl'\n",
    "test_texts, test_labels = load_and_process_data(test_file_name, label_map)\n",
    "tokenized_test = tokenize_data(test_texts)\n",
    "test_dataset = create_dataset(tokenized_test, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test dataset: {len(test_dataset)}\")\n",
    "\n",
    "label_map_inv = {0: \"꿈\", 1: \"일기\", 2: \"일정\", 3: \"메모\", 4: \"오류\"}\n",
    "\n",
    "# 모델 평가\n",
    "f1_scores = []\n",
    "\n",
    "for kfold in range(1, k + 1):\n",
    "    # 모델 로드\n",
    "    model = ElectraForSequenceClassification.from_pretrained(f\"/media/mydrive/models/text_classification/model_{kfold}\", num_labels=len(label_map)).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    logged_data = []\n",
    "    id_counter = 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            batch_input_ids, batch_attention_mask, batch_labels = [b.to(device) for b in batch]\n",
    "\n",
    "            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_true.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "            # 입력과 출력을 logged_data에 추가\n",
    "            for input_id, true_label, pred_label in zip(batch_input_ids, batch_labels, preds):\n",
    "                logged_data.append({\n",
    "                    \"id\": id_counter,\n",
    "                    \"input\": tokenizer.decode(input_id, skip_special_tokens=True),\n",
    "                    \"output\": label_map_inv[true_label.item()],\n",
    "                    \"predicted\": label_map_inv[pred_label],\n",
    "                })\n",
    "                id_counter += 1\n",
    "\n",
    "        # logged_data를 jsonl 파일로 저장\n",
    "        file_name = f\"/media/mydrive/datasets/text_classification_fold_{kfold}_test.jsonl\"\n",
    "        with open(file_name, 'w', encoding='utf-8') as f:\n",
    "            for data in logged_data:\n",
    "                json.dump(data, f, ensure_ascii=False)\n",
    "                f.write('\\n')\n",
    "\n",
    "    # F1 스코어 계산\n",
    "    f1 = f1_score(all_true, all_preds, average=\"macro\")\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"F1 Score for fold {kfold}: {f1}\")\n",
    "\n",
    "# 최종 평균 F1 스코어\n",
    "average_f1 = sum(f1_scores) / len(f1_scores)\n",
    "print(f\"Average F1 Score: {average_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 23, 'input': '내가 너한테 어떤 프롬프트를 작성해서 역할을 부여했더라?', 'output': '오류', 'predicted': '꿈'}\n",
      "{'id': 103, 'input': '환승연애 3을 봤는데 너무 재밌다', 'output': '일기', 'predicted': '메모'}\n",
      "{'id': 136, 'input': '커다란 모기가 나를 물어서 이마에 혹이 났어.', 'output': '일기', 'predicted': '꿈'}\n",
      "{'id': 139, 'input': '조태완', 'output': '메모', 'predicted': '오류'}\n",
      "{'id': 149, 'input': '3월 2일 개강', 'output': '일정', 'predicted': '오류'}\n",
      "{'id': 191, 'input': '1월 30일 수화', 'output': '일정', 'predicted': '메모'}\n",
      "{'id': 232, 'input': '일정 등록하고 싶어', 'output': '오류', 'predicted': '메모'}\n",
      "{'id': 275, 'input': '옆집 이웃과 낯술 한잔 볼수록 훌륭한 분들 곁에 이렇게 훌륭한 분들이 계셔서 행복함', 'output': '일기', 'predicted': '일정'}\n",
      "{'id': 284, 'input': '내가 너한테 어떤 프롬프트를 작성해서 역할을 부여했더라?', 'output': '오류', 'predicted': '꿈'}\n",
      "{'id': 343, 'input': '99월 42일 전우진 생일', 'output': '오류', 'predicted': '메모'}\n",
      "{'id': 413, 'input': '29일 30일 오전', 'output': '일정', 'predicted': '오류'}\n",
      "{'id': 429, 'input': '친구들과 동남아에 가서 골프를 치고 싶다. 여긴 추우니까.', 'output': '일기', 'predicted': '꿈'}\n",
      "{'id': 510, 'input': '2024 켈린더구매', 'output': '메모', 'predicted': '일정'}\n",
      "{'id': 521, 'input': '2024. 01. 09 화요일 감사일기 1. 눈이 많이 오고 있지만 미끄러지지않고 출근하게 해주심에 감사합니다. 2. 어제 하루 종일 머리가 너무 아프고 체한 것 같이 속이 정말 안 좋았었는데 오늘은 멀쩡히 그 어떤 것도 아프게 하지 않게 해주셔서 감사합니다. 3. 아침에 일어나 사랑하는 엄마 아빠 그리고 소복이의 얼굴을 보게 하게 하심에 감사합니다. 4. 기침도 점점 잦아들고 독감을 점점 낫게 하심에 감사합니다. 5. 종아리가 조금 아프지만 허리 디스크 수술도 잘 회복되고 있음에 감사합니다.', 'output': '일기', 'predicted': '메모'}\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "with open('/media/mydrive/datasets/text_classification_fold_1_test.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = json.loads(line)\n",
    "        if line[\"output\"] != line[\"predicted\"]:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500개의 데이터를 분석해본 결과 기존 gpt-4-turbo모델로 텍스트를 분류했을 때\n",
    "\n",
    "평균적으로 1개의 작업 당\n",
    "- 16.47원(2023.01.25 기준)의 비용이 들었습니다.\n",
    "- 1.32초의 시간이 걸렸습니다.\n",
    "\n",
    "f1-score는 0.673입니다.(but, 기존 방식에는 라벨의 갯수가 4개였다.)\n",
    "분류 정확도는 82.75%입니다.\n",
    "\n",
    "beomi/KcELECTRA-base-v2022 모델을 직접 학습해서 사용 시 평균 f1-score는 0.952입니다.\n",
    "\n",
    "이로써 기존 방식에 비해 매우 저렴한 비용으로 더 높은 정확도(f1-score기준: 1.4배)를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.0.4) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "    \n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token: Traceback (most recent call last):\n",
      "  File \"/home/dmz/.local/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/dmz/.local/lib/python3.10/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 45, in main\n",
      "    service.run()\n",
      "  File \"/home/dmz/.local/lib/python3.10/site-packages/huggingface_hub/commands/user.py\", line 101, in run\n",
      "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
      "  File \"/home/dmz/.local/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 100, in login\n",
      "    interpreter_login(new_session=new_session, write_permission=write_permission)\n",
      "  File \"/home/dmz/.local/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 161, in interpreter_login\n",
      "    token = getpass(\"Token: \")\n",
      "  File \"/usr/lib/python3.10/getpass.py\", line 77, in unix_getpass\n",
      "    passwd = _raw_input(prompt, stream, input=input)\n",
      "  File \"/usr/lib/python3.10/getpass.py\", line 146, in _raw_input\n",
      "    line = input.readline()\n",
      "  File \"/usr/lib/python3.10/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|████████████████████████████████████████████| 511M/511M [00:56<00:00, 9.13MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/taewan2002/text-classification-v1.0/commit/c5da8a8e660ffaba6729476edafed4d1318c0dc9', commit_message='Upload ElectraForSequenceClassification', commit_description='', oid='c5da8a8e660ffaba6729476edafed4d1318c0dc9', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 허깅페이스에 모델 업로드\n",
    "sota_model = 2\n",
    "model = ElectraForSequenceClassification.from_pretrained(f\"/media/mydrive/models/text_classification/model_{sota_model}\")\n",
    "\n",
    "model.save_pretrained(\"/media/mydrive/models/text_classification/huggingface_model\")\n",
    "model.push_to_hub(\"text-classification-v1.0\", use_auth_token=True, private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot 2024-01-25 at 6.54.15 PM.png](https://kr.object.ncloudstorage.com/docent/Screenshot%202024-01-25%20at%206.54.15%20PM.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text_classification)",
   "language": "python",
   "name": "text_classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
